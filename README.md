# Зачетное задание по курсу `Big Data Analytics: Approaches and Tools`

## Практические задания

### `Вариант 1`

Использование `kaggle.com` Набора Данных **`Hubway`** Для Расчета Ключевых Показателей Эффективности Совместного Использования Велосипедов. [Условие задания](https://github.com/BosenkoTM/BigDataWork/blob/main/variant_1_exam_calculate/examp_1.pdf)

### `Вариант 2`

Использование данных **`NYC_Taxi`** для Расчета Ключевых Показателей Эффективности. [Условие задания](https://github.com/BosenkoTM/BigDataWork/blob/main/variant_2_exam_calculate/examp_2.pdf)

### `Вариант 3`

Настройка и работа в **`Hadoop`**, **`HDFS`** и **`Yarn`**. [Условие задания](https://github.com/BosenkoTM/BigDataWork/blob/main/variant_3_exam_calculate/examp_3.pdf)

### `Вариант 4`

Установка, настройка и работа в **`Hive`**. [Условие задания](https://github.com/BosenkoTM/BigDataWork/tree/main/variant_4_exam_calculate)


## Теоретические вопросы

1.	Основные парадигмы теории Больших данных. Правило Мура. Правила Амдала. Виды распределенных систем в контексте больших данных.
2.	Распределенная файловая система Hadoop (`HDFS`).
3.	Менеджеры кластера: (`YARN`).
4.	Инструменты работы с большими данными `Hive` и  `HiveQL`.
5.	Инструменты работы с большими данными при пакетной обработке данных: Фреймворк `MapReduce`. 
6.	Инструменты работы с большими данными `Spark` и `PySpark`.
7.	Координатор: основные подходы при работе в `Zookeeper`.
8.	Инструменты работы с большими данными при потоковой передаче данных: `Apache Storm`, `Spark Streaming`, `Spark Structured Streaming`.
9.	Инструменты работы с большими данными на Графах: `Apache Giraph`, `Spark GraphX`.
10.	Контейнеры: основные подходы при работе  в `Docker`.
