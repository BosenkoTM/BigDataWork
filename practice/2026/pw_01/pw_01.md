# Практическая работа №1. Обработка и анализ данных с использованием экосистемы Hadoop и Apache Spark (PySpark)

---

## Цель работы
Освоение основ работы с распределенной файловой системой HDFS и фреймворком Apache Spark. Студенты научатся разворачивать среду, загружать данные в HDFS, обрабатывать большие объемы данных с помощью PySpark (RDD, DataFrame), применять SQL-запросы для бизнес-аналитики и визуализировать результаты.

**Задачи:**
-  Развернуть и настроить Apache Hadoop и Spark (используя предоставленный образ или Colab).
-  Выполнить операции загрузки данных (ETL) в распределенную файловую систему.
-  Провести очистку и предобработку данных.
-  Выполнить аналитические запросы с использованием Spark SQL.
-  Визуализировать результаты для поддержки принятия управленческих решений.

---

## Необходимое ПО и окружение
Для выполнения работы рекомендуется использовать виртуальную машину с образом **`ds_mgpu_Hadoop3+spark_3_4`**.

**Технические характеристики:**
*   OS: Ubuntu 20.04 LTS (или новее).
*   Java: 8 или 11+.
*   Hadoop: 3.x.
*   Apache Spark: 3.4.3.
*   Python: 3.12+ с библиотекой `pyspark`.
*   JupyterHub / Jupyter Notebook.

*Альтернатива.* Google Colab (с установкой pyspark), однако приоритет отдается работе в настроенной локальной среде с HDFS.

---

## Алгоритм выполнения задания в Apache Hadoop(образ ds_mgpu_Hadoop3+spark_3_4)

Все действия по управлению кластером выполняются от пользователя `hadoop`.

### Шаг 1. Запуск кластера
В терминале выполните вход и запуск служб:
```bash
sudo su - hadoop
start-dfs.sh
start-yarn.sh
```

### Шаг 2. Проверка работы
Убедитесь, что процессы запущены (NameNode, DataNode, ResourceManager, NodeManager):
```bash
jps
```

**Веб-интерфейсы для мониторинга:**
*   HDFS NameNode: [http://localhost:9870](http://localhost:9870)
*   YARN ResourceManager: [http://localhost:8088](http://localhost:8088)

### Шаг 3. Подготовка HDFS и загрузка данных
Вам необходимо создать директорию в распределенной файловой системе и загрузить туда исходные данные (датасеты).

-  **Создание директорий:**
    ```bash
    # Создание папки пользователя (пример)
    hdfs dfs -mkdir -p /user/hadoop/lab_01/input
    
    # Настройка прав доступа (при необходимости)
    hdfs dfs -chmod 775 /user/hadoop/lab_01
    ```

-  **Загрузка данных:**
    Предположим, ваши скачанные датасеты (CSV) находятся локально в `~/Downloads/data`.
    ```bash
    hdfs dfs -put /home/hadoop/Downloads/data/*.csv /user/hadoop/lab_01/input/
    ```

-  **Проверка загрузки:**
    ```bash
    hdfs dfs -ls /user/hadoop/lab_01/input/
    ```

### Шаг 4. Завершение работы (после выполнения всех заданий)
```bash
stop-yarn.sh
stop-dfs.sh
# Или полная остановка
stop-all.sh
```

---

## Методические указания к PySpark

Работа выполняется в **Jupyter Notebook** или скрипте Python.

### Подключение и загрузка
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, desc

# Инициализация сессии
spark = SparkSession.builder \
    .appName("Lab1_BusinessInformatics") \
    .master("local[*]") \
    .getOrCreate()

# Загрузка данных из HDFS
# Обратите внимание на протокол hdfs:// и путь
df = spark.read.option("header", "true") \
    .option("inferSchema", "true") \
    .csv("hdfs://localhost:9000/user/hadoop/lab_01/input/ваш_файл.csv")

# Проверка схемы
df.printSchema()
df.show(5)
```

### Анализ и SQL
Для использования SQL-запросов необходимо зарегистрировать DataFrame как временное представление:
```python
df.createOrReplaceTempView("sales_data")

result = spark.sql("""
    SELECT category, SUM(amount) as total_revenue
    FROM sales_data
    GROUP BY category
    ORDER BY total_revenue DESC
""")
result.show()
```

---

## Варианты индивидуальных заданий

**Инструкция по выбору данных:**
Поскольку задание требует решения бизнес-кейса, вам необходимо найти подходящий датасет (Open Source) на ресурсах: Kaggle, GitHub, UCI Machine Learning Repository или сгенерировать синтетические данные, подходящие под описание варианта. Ссылку на источник данных обязательно указать в отчете. Также возможно согласовать датасет с преподавателем, если он соответствует предметной области специальности Бизнес-информатика.

**Вариант выбирается согласно номеру студента в списке группы (всего 40 вариантов).**

| № | Бизнес-задача (Контекст) | **Задание 1 (HDFS + Spark Core)**<br>Загрузка, очистка, агрегация | **Задание 2 (Spark SQL)**<br>Глубокий анализ и метрики | **Задание 3 (Визуализация)**<br>Python (Matplotlib/Seaborn) |
|---|---|---|---|---|
| 1 | **Розничные продажи** | Загрузить данные о продажах. Очистить от пустых значений. Подсчитать общую выручку по категориям товаров. | Определить топ-10 товаров по выручке и среднюю стоимость чека в разрезе месяцев. | Столбчатая диаграмма продаж по месяцам с линией тренда. |
| 2 | **Банковские транзакции** | Загрузить лог транзакций. Отфильтровать неудачные операции. Найти клиентов с наибольшим числом транзакций. | Рассчитать средний чек транзакции по дням недели и временным интервалам (утро, день, вечер). | Тепловая карта (Heatmap) распределения транзакций: День недели vs Время суток. |
| 3 | **Складской учет** | Загрузить данные инвентаризации. Выявить товары, которые не двигались > 30 дней (неликвид). | Выявить товары с критически низким запасом (ниже точки заказа) и рассчитать коэффициент оборачиваемости. | Тепловая карта товарных остатков по категориям. |
| 4 | **Управление поставками** | Загрузить данные поставок. Очистить дубликаты. Оценить объемы поставок по каждому контрагенту. | Рассчитать среднее время задержки поставки (Lead Time) и процент срывов сроков по поставщикам. | Рейтинг надежности поставщиков (Scatter plot: Объем vs Задержка). |
| 5 | **Анализ возвратов (E-com)** | Загрузить лог возвратов. Сгруппировать по причинам возврата. | Рассчитать процент возвратов (Return Rate) по категориям товаров и брендам. | Круговая диаграмма (Donut chart) причин возвратов. |
| 6 | **Программа лояльности** | Загрузить данные карт лояльности. Сегментировать клиентов по уровням (Silver, Gold, etc.). | Определить корреляцию между накопленными баллами и частотой покупок (Frequency). | Boxplot распределения трат для каждого уровня лояльности. |
| 7 | **Пользовательские корзины** | Загрузить данные брошенных и оплаченных корзин. Найти топ-5 товаров, лежащих в брошенных корзинах. | Market Basket Analysis: Определить пары товаров, которые чаще всего покупают вместе. | Граф связей (Network graph) между топ-10 товарами. |
| 8 | **Маркетинговые акции** | Загрузить данные промо-кампаний. Сравнить продажи в дни акций и обычные дни. | Рассчитать ROI (Return on Investment) для различных типов акций по категориям. | Bar chart эффективности разных типов акций (выручка vs затраты). |
| 9 | **Сезонность спроса** | Загрузить исторические данные продаж (2-3 года). Выявить месяцы с пиковыми продажами. | Рассчитать сезонные коэффициенты для каждой категории товаров. | Линейный график сезонности продаж с разбивкой по годам. |
| 10 | **Ценообразование** | Загрузить историю изменений цен и объемов продаж. | Исследовать ценовую эластичность: как изменение цены влияло на объем спроса (корреляция). | Scatter plot: Цена vs Объем продаж с линией регрессии. |
| 11 | **Логистика доставки** | Загрузить маршрутные листы. Посчитать среднее время доставки по городам. | Рассчитать удельную стоимость доставки (Cost per order) по регионам и типам транспорта. | Географическая карта (или Bar chart) загруженности регионов. |
| 12 | **Анализ отзывов (NLP)** | Загрузить датасет отзывов. Классифицировать по длине текста и наличию ключевых слов ("плохо", "отлично"). | Определить средний рейтинг товаров по брендам и категориям. | Гистограмма распределения оценок (1-5 звезд). |
| 13 | **Отток подписчиков (Churn)** | Загрузить данные подписок. Разделить на активных и ушедших клиентов. | Рассчитать LTV (Lifetime Value) для разных когорт пользователей. | Воронка (Funnel chart) конверсии и оттока подписчиков. |
| 14 | **B2B Продажи** | Загрузить базу корпоративных продаж. Сегментировать клиентов по отраслям. | Определить средний размер контракта и цикл сделки по каждой отрасли. | Treemap: Структура продаж по отраслям и клиентам. |
| 15 | **Маркетплейсы** | Загрузить данные продаж с разных площадок (WB, Ozon и др.). Агрегировать выручку по площадкам. | Рассчитать чистую прибыль по площадкам с учетом комиссий и логистики. | Сравнительная диаграмма (Stacked Bar) выручки и расходов по площадкам. |
| 16 | **Эффективность скидок** | Загрузить историю продаж со скидками. Определить долю продаж с дисконтом > 20%. | Найти оптимальный размер скидки, максимизирующий маржинальную прибыль, а не оборот. | График зависимости прибыли от размера скидки. |
| 17 | **Рекламные каналы** | Загрузить данные по рекламному трафику. Посчитать клики (CTR) по каналам. | Рассчитать стоимость привлечения клиента (CAC) для каждого канала (CPC / Conversion Rate). | Диаграмма распределения маркетингового бюджета и полученных лидов. |
| 18 | **Ассортиментная матрица** | Загрузить номенклатуру и продажи. Выполнить ABC-анализ (на основе выручки). | Выявить наименее прибыльные товары (C-категория) и товары "Cash Cows". | Парето-диаграмма для ABC-анализа. |
| 19 | **HR-аналитика** | Загрузить данные о сотрудниках (выработка, часы). Очистить от уволенных. | Рассчитать производительность (Revenue per Employee) и средний стаж по отделам. | Рейтинг отделов по эффективности (Bar chart). |
| 20 | **Филиальная сеть** | Загрузить показатели работы филиалов. Сравнить оборот. | Рассчитать рентабельность (Profit Margin) каждого филиала. | Карта или диаграмма географии продаж с цветовой кодировкой прибыли. |
| 21 | **Конкурентный анализ** | Загрузить парсинг цен конкурентов. Сравнить со своими ценами. | Рассчитать индекс цен (Price Index) относительно рынка для каждой категории. | Radar chart (Лепестковая диаграмма) сравнения показателей с конкурентами. |
| 22 | **Управление затратами** | Загрузить таблицу операционных расходов (OPEX). Сгруппировать по статьям затрат. | Рассчитать себестоимость единицы продукции (Unit Cost) по категориям. | Waterfall chart (Каскадная диаграмма) структуры затрат. |
| 23 | **Контроль качества** | Загрузить логи производства/брака. Найти партии с максимальным процентом дефектов. | Определить корреляцию между производственной линией и процентом брака. | Control Chart (Контрольная карта Шухарта) или Bar chart по дефектам. |
| 24 | **Оптимизация закупок** | Загрузить историю закупок сырья. Посчитать средний объем партии. | Рассчитать оптимальный размер заказа (EOQ - Economic Order Quantity) для топ-10 материалов. | График затрат на хранение vs затрат на оформление заказа. |
| 25 | **Платежные системы** | Загрузить реестр платежей. Определить долю каждого метода оплаты. | Сравнить средний чек (AOV) при оплате картой, наличными и кредитом. | Pie chart популярных способов оплаты. |
| 26 | **Гарантийное обслуживание** | Загрузить данные гарантийных обращений. | Рассчитать Failure Rate (частоту поломок) для каждого года эксплуатации товара. | График "Ванна отказов" (Bathtub curve) или гистограмма обращений по сроку службы. |
| 27 | **Экспортная деятельность** | Загрузить таможенную статистику/экспорт. Сгруппировать по странам назначения. | Определить наиболее маржинальные направления (страны) экспорта. | Geo-map (Картограмма) объемов экспорта. |
| 28 | **Веб-аналитика** | Загрузить кликстрим (clickstream) данные. Посчитать уникальных пользователей. | Рассчитать конверсию в покупку (CR) для пользователей с мобильных и десктопных устройств. | Воронка продаж (Session -> Cart -> Order). |
| 29 | **Загрузка оборудования** | Загрузить телеметрию станков/серверов. Определить время простоя. | Рассчитать OEE (Overall Equipment Effectiveness) или % загрузки мощностей по часам. | График загрузки мощностей во времени (Time series). |
| 30 | **Документооборот** | Загрузить журнал обработки заявок/документов. | Определить "узкие места": на каком этапе документы задерживаются дольше всего (Process Mining). | Flowchart или диаграмма длительности этапов процесса. |
| 31 | **Страховые выплаты** | Загрузить данные о страховых случаях. Фильтрация мошеннических меток. | Рассчитать Loss Ratio (Убыточность) по регионам и типам страхования. | Heatmap убыточности по регионам. |
| 32 | **Недвижимость** | Загрузить данные о продажах жилья. Очистить выбросы в ценах. | Рассчитать среднюю стоимость кв. метра в зависимости от района и этажности. | Boxplot цен по районам города. |
| 33 | **Энергопотребление** | Загрузить данные smart-счетчиков. Агрегация по часам/дням. | Выявить паттерны пикового потребления для разных типов абонентов (пром/жилье). | Временной ряд потребления с выделением пиков. |
| 34 | **Телеком (Биллинг)** | Загрузить CDR (Call Detail Records). Подсчет длительности звонков. | Сегментация абонентов по ARPU (Average Revenue Per User) и потреблению трафика. | Scatter plot: Голосовой трафик vs Интернет трафик. |
| 35 | **Кредитный скоринг** | Загрузить историю выдачи кредитов. Разделить на "возврат" и "дефолт". | Сравнить портреты заемщиков (возраст, доход) в группах дефолта и возврата. | Histograms сравнения распределений дохода для двух групп. |
| 36 | **Образование (LMS)** | Загрузить логи активности студентов. Посчитать время на курсе. | Корреляция между временем онлайн и итоговой оценкой. Поиск "отстающих". | Scatter plot: Активность vs Оценка. |
| 37 | **Такси/Каршеринг** | Загрузить данные о поездках. Агрегация по районам старта/финиша. | Рассчитать среднюю скорость движения и средний чек в зависимости от времени суток и погоды (если есть). | Карта плотности заказов такси. |
| 38 | **Отельный бизнес** | Загрузить данные бронирований. Расчет % отмен. | Рассчитать RevPAR (Revenue Per Available Room) по сезонам и категориям номеров. | Line chart загрузки отеля и RevPAR по месяцам. |
| 39 | **IT Service Desk** | Загрузить тикеты поддержки. Группировка по типам инцидентов. | Рассчитать SLA (соблюдение сроков реакции) и MTTR (среднее время решения) по инженерам. | Bar chart выполнения SLA по отделам. |
| 40 | **Кибербезопасность** | Загрузить логи доступа (Access Logs). Фильтр по внешним IP. | Поиск аномалий: IP-адреса с количеством запросов, превышающим 3 сигмы от среднего. | Line chart количества запросов с выделением аномальных точек. |

---

## Требования к отчетности

Для сдачи работы необходимо создать **публичный репозиторий** на GitHub или GitVerse.

### Структура репозитория:
-  **`README.md`**:
    *   Описание задачи и выбранного варианта.
    *   Инструкция по запуску.
    *   Ссылка на источник данных.
-  **`lab_01.ipynb`** (или `.py`):
    *   Основной код решения.
    *   Код должен быть структурирован, снабжен комментариями.
-  **`Report.md`** (или PDF):
    *   **Введение.** Цель, постановка бизнес-задачи, описание данных.
    *   **Ход работы:**
        *   Скриншоты загрузки данных в HDFS (команды консоли).
        *   Скриншоты/код предварительной обработки (schema, null checks).
    *   **Анализ:**
        *   SQL-запросы и таблицы с результатами.
        *   Графики (Визуализация) с интерпретацией (что означает этот график для бизнеса).
    *   **Выводы.** Итоги о применимости Hadoop/Spark для данной задачи.

**Сдача.** Ссылка на репозиторий отправляется в систему Moodle.


### Критерии оценки практической работы (Максимум 20 баллов)

| Категория | Критерий | Баллы |
| :--- | :--- | :--- |
| **1. Работа с HDFS и средой (Техническая часть)** | **3 балла** | |
| | Успешное развертывание среды, создание директорий в HDFS и загрузка исходных данных. Приведены доказательства (скриншоты консоли/вывод команд `hdfs dfs -ls`). | 1 |
| | Правильная настройка прав доступа и структуры папок согласно заданию. | 1 |
| | Данные корректно считаны из HDFS в Spark DataFrame (указан правильный URI `hdfs://...`). | 1 |
| **2. Реализация логики на PySpark и Spark SQL** | **8 баллов** | |
| **Задание 1 (ETL)** | Выполнена загрузка, очистка данных (обработка NULL, дубликатов), типизация колонок. Использованы методы Spark Core/DataFrame API. | 3 |
| **Задание 2 (SQL)** | Выполнен глубокий анализ данных с использованием Spark SQL. Написаны сложные запросы (агрегация, группировка, сортировка, фильтрация). Результаты соответствуют варианту задания. | 5 |
| **3. Визуализация и бизнес-интерпретация** | **5 баллов** | |
| **Задание 3 (Viz)** | Построены графики/диаграммы с использованием Matplotlib/Seaborn. Графики читаемы (есть легенда, подписи осей, заголовок). | 2 |
| **Аналитика** | Приведена интерпретация полученных результатов. Сделан вывод, полезный для бизнеса (ответ на вопрос "Что значат эти цифры?"). | 3 |
| **4. Оформление и культура кода** | **4 балла** | |
| **Репозиторий** | Репозиторий на GitHub/GitVerse создан корректно. Присутствует `README.md` с описанием проекта, инструкцией по запуску и ссылкой на источник данных. | 2 |
| **Отчет** | Отчет (PDF/Markdown) содержит введение, описание хода работы, код с пояснениями, скриншоты и итоговые выводы. Код структурирован, есть комментарии. | 2 |
| **Итого** | | **20** |