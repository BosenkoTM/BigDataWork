# Теоретические вопросы к курсу "Инструменты хранения и анализа больших данных"

## Раздел 1. Экосистема Hadoop и основы Big Data

1.  **Архитектура HDFS.** Опишите роли NameNode и DataNode. Как обеспечивается отказоустойчивость и репликация данных в HDFS?
2.  **YARN.** Какова роль YARN в экосистеме Hadoop? Опишите функции ResourceManager и NodeManager.
3.  **Парадигма MapReduce.** Объясните этапы Map, Shuffle и Reduce. В чем заключаются основные ограничения классического MapReduce для итеративных алгоритмов?
4.  **Форматы файлов.** Сравните строковые (CSV, JSON) и колоночные (Parquet, ORC) форматы данных. В каких случаях предпочтительнее использовать Parquet?
5.  **Жизненный цикл Big Data.** Перечислите основные этапы работы с большими данными от сбора до принятия бизнес-решений.

## Раздел 2. Apache Spark (Core и SQL)

6.  **Архитектура Spark.** Опишите компоненты Driver, Executor и Cluster Manager. Как они взаимодействуют при запуске приложения?
7.  **RDD (Resilient Distributed Dataset).** Что это такое? Объясните свойства неизменяемости (immutability) и распределенности.
8.  **Lazy Evaluation (Ленивые вычисления).** В чем суть ленивых вычислений в Spark? Чем отличаются Трансформации (Transformations) от Действий (Actions)? Приведите примеры.
9.  **DAG (Directed Acyclic Graph).** Что такое DAG в Spark и какую роль он играет в оптимизации плана выполнения задач?
10. **Spark DataFrame и Dataset.** В чем отличие DataFrame от RDD? Какие преимущества дает использование Catalyst Optimizer?
11. **Операция Shuffle.** Что такое Shuffle в Spark, когда он возникает (узкие vs широкие трансформации) и как он влияет на производительность?
12. **Управление памятью и кэширование.** В чем разница между методами `cache()` и `persist()`? Когда стоит кэшировать данные?

## Раздел 3. NoSQL и хранение данных

13. **Теорема CAP.** Сформулируйте теорему CAP. Объясните на примерах баз данных (MongoDB, Cassandra, RDBMS), какие две характеристики они обычно гарантируют.
14. **Документо-ориентированные СУБД (MongoDB).** Особенности модели данных (BSON/JSON). Понятие коллекции и документа. Когда стоит выбрать MongoDB?
15. **Колоночные СУБД (Cassandra).** Архитектура (кольцо, peer-to-peer), понятие Keyspace и Column Family. В чем особенность модели согласованности в Cassandra?
16. **СУБД Ключ-Значение (Redis).** Особенности Redis как in-memory базы данных. Основные сценарии использования (кэширование, сессии, очереди).
17. **Графовые СУБД (Neo4j, GraphDB).** Чем граф знаний отличается от реляционной модели? Что такое узлы, ребра и свойства? Примеры задач, решаемых графовыми БД.
18. **Полиглотное хранение (Polyglot Persistence).** Что означает этот термин и почему в современной архитектуре используется несколько типов БД одновременно?

## Раздел 4. Машинное обучение (Spark MLlib)

19. **Структура ML Pipeline.** Объясните концепцию Pipeline в Spark ML. В чем разница между Transformer и Estimator?
20. **Feature Engineering в Spark.** Для чего используются VectorAssembler, StringIndexer и OneHotEncoder? Почему модели MLlib требуют данные в векторном формате?
21. **Оценка моделей.** Какие метрики используются для оценки качества задач регрессии (RMSE, R2) и классификации (ROC-AUC, F1-score)?
22. **Параллелизм в ML.** Как Spark MLlib распараллеливает процесс обучения моделей (например, Random Forest или K-Means)?

## Раздел 5. AutoML и продвинутая аналитика (H2O, AutoGluon)

23. **Концепция AutoML.** Какую проблему решает автоматическое машинное обучение? Какие этапы работы Data Scientist оно автоматизирует?
24. **H2O.ai.** Опишите архитектуру H2O. Что такое Sparkling Water и как она интегрирует H2O со Spark?
25. **AutoGluon.** В чем особенности подхода AutoGluon к табличным данным? Что такое Multi-layer Stacking и как он повышает точность?
26. **Интерпретируемость моделей (Explainable AI).** Почему важно понимать, как модель принимает решения? Что такое Shapley Values и Feature Importance?
27. **Обработка текста в AutoML.** Как современные инструменты (например, AutoGluon) работают с текстовыми признаками (NLP, BERT) в рамках табличных задач?
28. **Transfer Learning (Трансферное обучение).** Что это такое и как оно применяется в задачах компьютерного зрения или NLP в рамках AutoML?
29. **Развертывание моделей (Deployment).** Что такое форматы POJO/MOJO в H2O и зачем они нужны для внедрения моделей в продакшн?
30. **Сравнение подходов.** В каких случаях лучше использовать Spark MLlib (ручное построение пайплайна), а в каких — инструменты AutoML (H2O, AutoGluon)?